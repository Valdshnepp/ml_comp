{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6daddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (138039, 26)\n",
      "test shape: (59159, 25)\n",
      "positive rate: 0.07734770608306349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_fake</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>title_name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>...</th>\n",
       "      <th>item_count_sales7</th>\n",
       "      <th>item_count_sales30</th>\n",
       "      <th>item_count_sales90</th>\n",
       "      <th>item_count_returns7</th>\n",
       "      <th>item_count_returns30</th>\n",
       "      <th>item_count_returns90</th>\n",
       "      <th>item_variety_count</th>\n",
       "      <th>item_available_count</th>\n",
       "      <th>seller_time_alive</th>\n",
       "      <th>seller_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ACTRUM</td>\n",
       "      <td>Мешки пылесборники для пылесоса PHILIPS, 10 шт...</td>\n",
       "      <td>Мешки для пылесоса PHILIPS TRIATLON, синтетиче...</td>\n",
       "      <td>Пылесборник</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Line</td>\n",
       "      <td>Защитная силиконовая крышка обьектива GoPro He...</td>\n",
       "      <td>Защитная крышка Redline на экшн-камеру GoPro (...</td>\n",
       "      <td>Крышка для объектива</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_fake     brand                                        description  \\\n",
       "0   0        0    ACTRUM  Мешки пылесборники для пылесоса PHILIPS, 10 шт...   \n",
       "1   1        0  Red Line  Защитная силиконовая крышка обьектива GoPro He...   \n",
       "\n",
       "                                          title_name              category  \\\n",
       "0  Мешки для пылесоса PHILIPS TRIATLON, синтетиче...           Пылесборник   \n",
       "1  Защитная крышка Redline на экшн-камеру GoPro (...  Крышка для объектива   \n",
       "\n",
       "   rating_1_count  rating_2_count  rating_3_count  rating_4_count  ...  \\\n",
       "0             6.0             4.0             4.0             3.0  ...   \n",
       "1             NaN             NaN             NaN             NaN  ...   \n",
       "\n",
       "   item_count_sales7  item_count_sales30  item_count_sales90  \\\n",
       "0                  2                  19                  61   \n",
       "1                  0                   0                   0   \n",
       "\n",
       "   item_count_returns7  item_count_returns30  item_count_returns90  \\\n",
       "0                    0                     0                     1   \n",
       "1                    0                     0                     0   \n",
       "\n",
       "   item_variety_count  item_available_count  seller_time_alive  seller_id  \n",
       "0                 1.0                   1.0             1860.0       1218  \n",
       "1                 1.0                   1.0             1757.0       1374  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test_X.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print('train shape:', train_df.shape)\n",
    "print('test shape:', test_df.shape)\n",
    "print('positive rate:', float(train_df['is_fake'].mean()))\n",
    "\n",
    "train_df[['title_name','description','brand','category']] = train_df[['title_name','description','brand','category']].fillna('')\n",
    "test_df[['title_name','description','brand','category']] = test_df[['title_name','description','brand','category']].fillna('')\n",
    "\n",
    "train_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e6deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand:actrum cat:пылесборник empty_title:0 empty_desc:0 empty_brand:0 empty_cat:0 title:мешки для пылесоса philips triatlon, синтетические, многослойные, тип: hr 6947 desc:мешки пылесборники для пылесоса philips, 10 шт., синтетические, многослойные, бренд: actrum, арт. ak-10/10, тип оригинального ме\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(s):\n",
    "    s = str(s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'<[^>]+>', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def make_text(df: pd.DataFrame) -> pd.Series:\n",
    "    title_raw = df['title_name'].fillna('').astype(str)\n",
    "    desc_raw = df['description'].fillna('').astype(str)\n",
    "    brand_raw = df['brand'].fillna('').astype(str)\n",
    "    cat_raw = df['category'].fillna('').astype(str)\n",
    "\n",
    "    empty_title = (title_raw.str.strip() == '').astype(int).astype(str)\n",
    "    empty_desc = (desc_raw.str.strip() == '').astype(int).astype(str)\n",
    "    empty_brand = (brand_raw.str.strip() == '').astype(int).astype(str)\n",
    "    empty_cat = (cat_raw.str.strip() == '').astype(int).astype(str)\n",
    "\n",
    "    title = df['title_name'].map(normalize_text)\n",
    "    desc = df['description'].map(normalize_text)\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    brand = df['brand'].map(normalize_text)\n",
    "    cat = df['category'].map(normalize_text)\n",
    "    parts.append('brand:' + brand)\n",
    "    parts.append('cat:' + cat)\n",
    "\n",
    "    parts.append('empty_title:' + empty_title)\n",
    "    parts.append('empty_desc:' + empty_desc)\n",
    "    parts.append('empty_brand:' + empty_brand)\n",
    "    parts.append('empty_cat:' + empty_cat)\n",
    "\n",
    "    parts.append('title:' + title)\n",
    "    parts.append('desc:' + desc)\n",
    "\n",
    "    out = parts[0]\n",
    "    for p in parts[1:]:\n",
    "        out = out + ' ' + p\n",
    "    return out\n",
    "\n",
    "X_text = make_text(train_df)\n",
    "X_test_text = make_text(test_df)\n",
    "y = train_df['is_fake'].astype(int).values\n",
    "\n",
    "print(X_text.iloc[0][:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (138039, 270000)\n",
      "X_test shape: (59159, 270000)\n"
     ]
    }
   ],
   "source": [
    "word_tfidf = TfidfVectorizer(\n",
    "    max_features=120_000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    token_pattern=r'(?u)\\b\\w+\\b',\n",
    "    lowercase=False,\n",
    ")\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    max_features=150_000,\n",
    "    analyzer='char_wb',\n",
    "    ngram_range=(3, 6),\n",
    "    min_df=3,\n",
    ")\n",
    "\n",
    "Xw = word_tfidf.fit_transform(X_text)\n",
    "Xc = char_tfidf.fit_transform(X_text)\n",
    "X = hstack([Xw, Xc]).tocsr()\n",
    "\n",
    "Xw_test = word_tfidf.transform(X_test_text)\n",
    "Xc_test = char_tfidf.transform(X_test_text)\n",
    "X_test = hstack([Xw_test, Xc_test]).tocsr()\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19428fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params = dict(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    alpha=3e-6,\n",
    "    l1_ratio=0.15,\n",
    "    class_weight='balanced',\n",
    "    max_iter=3000,\n",
    "    tol=1e-3,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "clf_params = dict(\n",
    "    loss='log_loss',    \n",
    "    penalty='elasticnet',\n",
    "    alpha=3e-6,\n",
    "    l1_ratio=0,\n",
    "    class_weight='balanced',\n",
    "    max_iter=3000,\n",
    "    tol=1e-3,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0e4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params = dict(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    alpha=1e-6,\n",
    "    l1_ratio=0.3, # 0.3\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    "    random_state=RANDOM_STATE+3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4064b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new_tdata/sub_text.csv (59159, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138039</td>\n",
       "      <td>0.020363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138040</td>\n",
       "      <td>0.048996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138041</td>\n",
       "      <td>0.027560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138042</td>\n",
       "      <td>0.029574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138043</td>\n",
       "      <td>0.017317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   is_fake\n",
       "0  138039  0.020363\n",
       "1  138040  0.048996\n",
       "2  138041  0.027560\n",
       "3  138042  0.029574\n",
       "4  138043  0.017317"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(**clf_params)\n",
    "clf.fit(X, y)\n",
    "\n",
    "test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "sub_text = pd.DataFrame({'id': test_df['id'].values, 'is_fake': test_proba})\n",
    "sub_text.to_csv('new_tdata/sub_text.csv', index=False)\n",
    "print('Saved new_tdata/sub_text.csv', sub_text.shape)\n",
    "sub_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bfdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params = dict(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    alpha=1e-6, #1e-6\n",
    "    l1_ratio=0.15, # 0.15\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    "    random_state=RANDOM_STATE+3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef284534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit sgd_a3e-6_l10.00_rs1_1\n",
      "fit sgd_a3e-6_l10.00_rs1_2\n",
      "fit sgd_a3e-6_l10.00_rs1_3\n",
      "fit sgd_a1e-6_l10.10_rs3_7\n",
      "fit sgd_a1e-6_l10.10_rs3_7\n",
      "fit sgd_a1e-5_l10.00_rs4_8\n",
      "saved new_tdata/sub_text_sgd_ens_fullfit_rank.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Requires that X, X_test, y, test_df already exist.\n",
    "\n",
    "MODEL_CFGS = [\n",
    "    dict(name='sgd_a3e-6_l10.00_rs1_1', alpha=1e-6, l1_ratio=0.15, random_state=RANDOM_STATE+1),\n",
    "    dict(name='sgd_a3e-6_l10.00_rs1_2', alpha=1e-6, l1_ratio=0.15, random_state=RANDOM_STATE+2),\n",
    "    dict(name='sgd_a3e-6_l10.00_rs1_3', alpha=1e-6, l1_ratio=0.15, random_state=RANDOM_STATE+3),\n",
    "    # dict(name='sgd_a3e-6_l10.00_rs1_4', alpha=3e-6, l1_ratio=0.2, random_state=RANDOM_STATE+4),\n",
    "    # dict(name='sgd_a3e-6_l10.00_rs1_5', alpha=3e-6, l1_ratio=0.2, random_state=RANDOM_STATE+5),\n",
    "    # dict(name='sgd_a3e-6_l10.05_rs2_6', alpha=3e-6, l1_ratio=0.2, random_state=RANDOM_STATE+6),\n",
    "    dict(name='sgd_a1e-6_l10.10_rs3_7', alpha=1e-6, l1_ratio=0.2, random_state=RANDOM_STATE+6),\n",
    "    dict(name='sgd_a1e-6_l10.10_rs3_7', alpha=1e-6, l1_ratio=0.2, random_state=RANDOM_STATE+7),\n",
    "    dict(name='sgd_a1e-5_l10.00_rs4_8', alpha=1e-6, l1_ratio=0.15, random_state=RANDOM_STATE+8),\n",
    "    # dict(name='sgd_a1e-6_l10.20_rs5_9', alpha=1e-6, l1_ratio=0.20, random_state=RANDOM_STATE+9),\n",
    "]\n",
    "\n",
    "base_params = dict(\n",
    "    loss='log_loss',\n",
    "    penalty='elasticnet',\n",
    "    class_weight='balanced',\n",
    "    max_iter=2000,\n",
    "    tol=1e-3,\n",
    ")\n",
    "\n",
    "preds = []\n",
    "for cfg in MODEL_CFGS:\n",
    "    print('fit', cfg['name'])\n",
    "    params = dict(base_params)\n",
    "    params.update({k: v for k, v in cfg.items() if k != 'name'})\n",
    "\n",
    "    clf = SGDClassifier(**params)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    preds.append(clf.predict_proba(X_test)[:, 1].astype(float))\n",
    "\n",
    "P = np.vstack(preds)  # (n_models, n_test)\n",
    "\n",
    "\n",
    "def to_rank01(x: np.ndarray) -> np.ndarray:\n",
    "    order = x.argsort(kind='mergesort')\n",
    "    ranks = np.empty_like(order, dtype=float)\n",
    "    ranks[order] = np.linspace(0.0, 1.0, num=len(x), endpoint=True)\n",
    "    return ranks\n",
    "\n",
    "R = np.vstack([to_rank01(P[i]) for i in range(P.shape[0])])\n",
    "r_mean = R.mean(axis=0)\n",
    "out_rank = 'new_tdata/sub_text_sgd_ens_fullfit_rank.csv'\n",
    "pd.DataFrame({'id': test_df['id'].values, 'is_fake': r_mean}).to_csv(out_rank, index=False)\n",
    "print('saved', out_rank)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
